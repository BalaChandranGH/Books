{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e56d6607-737f-4ecc-81e3-e69b06a1b704",
   "metadata": {},
   "source": [
    "<!--BOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures/MLPG-Book-Cover-Small.png\"><br>\n",
    "\n",
    "This notebook contains an excerpt from the **`Machine Learning Project Guidelines - For Beginners`** book written by *Balasubramanian Chandran*; the content is available [on GitHub](https://github.com/BalaChandranGH/Books/ML-Project-Guidelines)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8354d1e2-a263-4eed-9aef-8dc816dec603",
   "metadata": {},
   "source": [
    "<br>\n",
    "<!--NAVIGATION-->\n",
    "\n",
    "<[ [Stage-1: Business Understanding](07.00-mlpg-Stage-1-Business-Understanding.ipynb) | [Contents and Acronyms](00.00-mlpg-Contents-and-Acronyms.ipynb) | [Stage-3: Research](09.00-mlpg-Stage-3-Research.ipynb) ]>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c10ed58-69c3-4bc7-a54f-c863ac4ddea4",
   "metadata": {},
   "source": [
    "# 8. Stage-2: Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a333e5be-4753-4e8c-85de-7e398bb81962",
   "metadata": {},
   "source": [
    "It's assumed that, at this stage, the following are already made available by the DS team. EDA is the main focus of the ML team.\n",
    "* Data requirements definition identifying the following:\n",
    "  - Data sources (and they could be)\n",
    "    - In-house or external source\n",
    "    - APIs, XML feeds, CSVs, Excel files\n",
    "    - Data mining/ scrapping from online\n",
    "  - Data pipelines (and they could be)\n",
    "    - Streaming vs Batch\n",
    "    - Ingestion frequency\n",
    "  - Data environments\n",
    "    - Small vs Medium vs Big data\n",
    "* Collected raw datasets (and they should be)\n",
    "  - Diverse\n",
    "  - Unbiased\n",
    "  - Abundant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4199a3fd-9132-45be-9f11-afbb02107caa",
   "metadata": {},
   "source": [
    "## 8.1. Exploratory Data Analysis (EDA)\n",
    "### 8.1.1. Objectives of EDA\n",
    "* To get an overview of the distribution of the dataset\n",
    "* Check for missing numerical values, outliers, or other anomalies in the dataset\n",
    "* Discover patterns and relationships between variables in the dataset\n",
    "* Check the underlying assumptions in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16692aa-c0c1-4f2e-a96c-431d2923609a",
   "metadata": {},
   "source": [
    "### 8.1.2. Prerequisites of EDA\n",
    "* _**NumPy**_: Python library for scientific computing supporting multi-dimensional arrays, matrices, and high-level mathematical functions\n",
    "* _**Pandas**_: Python library for data analysis and manipulation\n",
    "* _**Matplotlib**_: A core data visualization library for Python with an object-oriented API for embedding plots into applications\n",
    "* _**Seaborn**_: A data visualization library for Python built on top of Matplotlib providing high-level visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e8dd03-014e-4a1c-b3ad-34096aee0e0b",
   "metadata": {},
   "source": [
    "### 8.1.3. Types of variables\n",
    "**`A) Numeric/Quantitative variables`**: contain numerical data. They can be further classified into two categories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96dd857-bef6-4c74-a1d8-dafd349eea3c",
   "metadata": {},
   "source": [
    "**Integer/Discrete variables:**\n",
    "* These are numeric variables that have a finite number of countable values between any two values\n",
    "* A discrete variable is always numeric and whole (1, 2, 3, 5, 10, 50, etc.)\n",
    "* Examples:\n",
    "  - The number of customer complaints\n",
    "  - The number of flaws or defects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e05c27d-d7ae-4474-bf61-2327d79cdffd",
   "metadata": {},
   "source": [
    "**Float/Continuous variables:**\n",
    "* These are numeric variables that have an infinite number of values between any two values\n",
    "* A continuous variable can be numeric and float (0.1, 0.2, 0.3, etc.) or date/time\n",
    "* Examples:\n",
    "  - Income\n",
    "  - Temperature\n",
    "  - Height\n",
    "  - Weight\n",
    "  - Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12298b6c-8ccf-4a0d-a22c-dfd5f4c8b859",
   "metadata": {},
   "source": [
    "**Interval variable:**\n",
    "* It takes numeric values and may be classified as a continuous variable type\n",
    "* Arithmetic operations can be performed on interval variables. However, these operations are restricted to only addition and subtraction\n",
    "* The interval variable is an extension of the ordinal variable. In other words, we could say interval variables are built upon ordinary variables\n",
    "* The intervals on the scale are equal in an interval variable. The scale is equidistant (equally spaced)\n",
    "* The variables are measured using an interval scale, which not only shows the order but also shows the exact difference in the value\n",
    "* It has no zero value\n",
    "* Examples:\n",
    "  - Temperature\n",
    "  - Time\n",
    "  - CGPA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47c2935-4610-4769-af62-ee5bf441b68c",
   "metadata": {},
   "source": [
    "**Ratio variable:**\n",
    "* Ratio variables have absolute zero characteristics\n",
    "* The zero point makes is what makes it possible to measure multiple values and perform multiplication and division operations. Therefore, we can say that an object is twice as big or as long as another\n",
    "* It has an intrinsic order with an equidistant scale, i.e, all the levels in the ratio scale have an equal distance\n",
    "* Due to the absolute point characteristics of a ratio variable, it doesn’t have a negative number like an interval variable. Therefore, before measuring any object on a ratio scale, researchers need to first study if it satisfies all the properties of an interval variable and also the zero point characteristic\n",
    "* The ratio variable is the peak type of measurement variable in statistical analysis. It allows for the addition, interaction, multiplication, and division of variables\n",
    "* Also, all statistical analyses including mean, mode, median, etc. can be calculated on the ratio scale\n",
    "* Examples:\n",
    "  - Height\n",
    "  - Weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdde4e43-0815-4b21-ae2c-7c1df5060e08",
   "metadata": {},
   "source": [
    "**`B) Categorical/Qualitative variables`**: are variables that describe a particular category. Usually, they take on one of several fixed variables. Eg.,\n",
    "* The category “hair color” could contain the categorical variables “black,” “brown,” “blonde,” and “red.”\n",
    "* The category “gender” could contain the categorical variables “Male” or “Female”.\n",
    "\n",
    "We can divide categorical data into three types: Nominal data, Ordinal data & Boolean data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075e4af8-e22a-4723-a3d9-1127ff96f33f",
   "metadata": {},
   "source": [
    "**Nominal variable:**\n",
    "* A variable that has two or more categories\n",
    "* There is no ordering involved with this type of variable and there is no agreed way to order these from highest to lowest\n",
    "* A nominal variable is qualitative, which means numbers are used here only to categorize or identify objects\n",
    "* They can also take quantitative values, however, these quantitative values do not have numeric properties, i.e., arithmetic operations cannot be performed on them\n",
    "* Examples:\n",
    "  - Gender - male, female\n",
    "  - Color - red, green, blue, black, etc.\n",
    "  - Hair color - black, blonde, brown, brunette, red, etc.\n",
    "  - Name - AAAAA, BBBBB, CCCCC, etc.\n",
    "  - phone no. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756a1246-b26c-4740-80e8-6d31a07b4c91",
   "metadata": {},
   "source": [
    "**Ordinal variable:**\n",
    "* It is an extension of Nominal data\n",
    "* It has a rank or order\n",
    "* It establishes a relative rank\n",
    "* It has no standardized interval scale\n",
    "* It measures qualitative traits\n",
    "* The median and mode can be analyzed\n",
    "* There are 2 types of Ordinal variables and they are:\n",
    "  - Ordinal Variable with Numeric Value\n",
    "    - Example 1: How satisfied are you (on a scale of 1 - 5)?\n",
    "      1. Very satisfied \n",
    "      2. Satisfied\n",
    "      3. Indifferent\n",
    "      4. Dissatisfied \n",
    "      5. Very dissatisfied\n",
    "    - Example 2: What is your age group (on a scale of 1 - 3)?\n",
    "      1. Low (13-19 years)\n",
    "      2. Medium (20-50 years)\n",
    "      3. High (51-99 years)\n",
    "  - Ordinal Variable without Numeric Value\n",
    "    - Example 1: How satisfied are you?\n",
    "      * Very satisfied \n",
    "      * Satisfied\n",
    "      * Indifferent\n",
    "      * Dissatisfied \n",
    "      * Very dissatisfied\n",
    "    - Example 2: What is your age group?\n",
    "      * Low (13-19 years)\n",
    "      * Medium (20-50 years)\n",
    "      * High (51-99 years)\n",
    "* Differences Between Nominal and Ordinal Variable\n",
    "  - The ordinal variable has an intrinsic order while nominal variables do not have an order\n",
    "  - It is only the mode of a nominal variable that can be analyzed while analysis like the median, mode, quantile, percentile, etc. can be performed on ordinal variables\n",
    "  - The tests carried on nominal and ordinal variables are different\n",
    "* Similarities Between Nominal and Ordinal Variable\n",
    "  - They are both types of categorical variables\n",
    "  - They both have an inconclusive mean and a mode\n",
    "  - They are both visualized using bar charts and pie charts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bffcaf-f42d-4e39-aa09-360514c6bc94",
   "metadata": {},
   "source": [
    "**Boolean variable:**\n",
    "* A variable that has only two states such as True or False (or) Yes or No (or) 1 or 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cb94f2-7016-4e8d-92e4-e39f887dbc95",
   "metadata": {},
   "source": [
    "![](figures/MLPG-TypesOfVariables.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9021b5c7-1ad7-4505-8eb0-ae3c300bcc44",
   "metadata": {},
   "source": [
    "### 8.1.4. Distribution of Variables\n",
    "**Univariate distribution**: There is only one variable under consideration. It is the simplest form of analysis because only one quantity changes. It does not deal with causes or relationships. The main purpose of the analysis is to describe the data and find patterns that exist within it. An example of univariate data can be the height of a single person. We can describe patterns found in univariate data using central tendency (mean, median, and mode) and dispersion (range, variance, standard deviation, maximum and minimum values, and interquartile range). We can visualize the univariate data using various types of charts and graphs. These are frequency distribution tables, histograms, bar charts, pie charts, and frequency polygons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d069a3-d27d-4a3c-b90d-76d5eb1d27a7",
   "metadata": {},
   "source": [
    "**Bivariate distribution**: This type of data distribution involves two different variables. The analysis of this type of data deals with causes and relationships and the analysis is done to find out the relationship between the two variables. A very common example of bivariate distribution is the height and weight of a single person. It is one of the simplest forms of statistical analysis, used to find out if there is a relationship between two sets of values. Thus, bivariate data analysis involves comparisons, exploring relationships, and finding causes and explanations. These variables are often plotted on the X and Y-axis on the graph for a better understanding of the data and one of these variables is independent while the other is dependent. Common types of bivariate analysis include drawing scatter plots, regression analysis, and finding correlation coefficients. A scatter plot is used to find out if there exists any relationship between two variables. Regression analysis is a statistical method for estimating the relationships between variables. Correlation coefficient analysis measures the strength and direction of a linear relationship between two variables on a scatter plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6ce39b-d509-4038-854e-cc334f2bdb74",
   "metadata": {},
   "source": [
    "**Multivariate distribution**: When the dataset involves three or more variables, it is categorized under multivariate distribution. Multivariate analysis is used to study more complex sets of data. It is usually unsuitable for small sets of data. There are a wide variety of analysis techniques to perform multivariate analysis. The choice of analysis techniques depends on the dataset and our goals to be achieved. Some examples of multivariate analysis techniques are additive tree, cluster analysis, correspondence analysis, factor analysis, MANOVA (multivariate analysis of variance), multidimensional scaling, multiple regression analysis, principal component analysis, and redundancy analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff05ee8-d6a9-4179-9139-bdc2de065743",
   "metadata": {},
   "source": [
    "### 8.1.5. Summary of EDA Techniques\n",
    "EDA techniques depend on the type of data and the objectives of the analysis. The following is a summary of useful EDA techniques:\n",
    "```\n",
    "    Type of data                EDA techniques\n",
    "    -------------------------   ----------------------\n",
    "    Categorical                 Descriptive statistics\n",
    "    Univariate discrete         Barplot\n",
    "    Univariate continuous       Line plot, Histogram\n",
    "    Bivariate continuous        2-D scatter plot\n",
    "    2-D arrays                  Heatmap\n",
    "    Multivariate distribution   3-D scatter plot\n",
    "    Multiple groups             Boxplot\n",
    "```\n",
    "The following table summarizes the useful EDA techniques depending on the objective:\n",
    "```\n",
    "    Objective                                      EDA techniques\n",
    "    --------------------------------------------   ----------------------------------------------\n",
    "    Check the distribution of a variable           Histogram\n",
    "    Find outliers                                  Histogram, scatterplot, box-and-whisker plot\n",
    "    Quantify the relationship between variables    2-D scatter plot, covariance, and correlation\n",
    "    Visualize the relationship between variables   Heatmap\n",
    "    Visualize high-dimensional data                Principal component analysis, 3-D scatter plot\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7786936-50fb-462c-88b3-429d997f29e2",
   "metadata": {},
   "source": [
    "### 8.1.6. Text EDA: Understand the data with Descriptive Statistics\n",
    "* Dimensions of the dataset\n",
    "* An initial look at the raw data (e.g., first 10 rows & last 10 rows)\n",
    "* Basic information of the dataset\n",
    "* Statistical summary of the dataset\n",
    "* Class distribution of the dataset\n",
    "* Explore NA / NULL values in the dataset\n",
    "* Explore duplicates in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e7e865-de55-4b27-9a78-d7b026570ff3",
   "metadata": {},
   "source": [
    "### 8.1.7. Visual EDA: Understand the data with Visualizations\n",
    "* Draw Univariate plots to better understand each attribute\n",
    "  - Box and Whisker plots\n",
    "  - Histograms\n",
    "  - Pie-charts or Bar-charts (horizontal or vertical) to understand the distributions of data in int or float data-type\n",
    "* Draw Multivariate plots to better understand the relationships between attributes\n",
    "  - Scatter Plot Matrix\n",
    "  - Correlation maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf10890-04d0-4e7a-84e7-81632681fcad",
   "metadata": {},
   "source": [
    "## 8.2. Deliverables from Stage-2\n",
    "* Data requirements definition\n",
    "* Collected raw datasets & their metadata\n",
    "* Raw data summary report\n",
    "* Exploratory Data Analysis (EDA) report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45de7045-1102-4f2c-b654-1c36c2bd4388",
   "metadata": {},
   "source": [
    "## 8.3. Notebook development tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcf91f8-d5f5-4ae0-9a10-a59e252da342",
   "metadata": {},
   "outputs": [],
   "source": [
    "###   (2.1) IMPORT LIBRARIES, MODULES, FUNCTIONS, OBJECTS   ###\n",
    "\n",
    "## Import necessary libraries for this project. Examples are given below ##\n",
    "# import sys         as sys\n",
    "# import csv         as csv\n",
    "# import numpy       as np\n",
    "# import pandas      as pd\n",
    "# import sklearn     as sk\n",
    "# import scipy       as sp\n",
    "# import seaborn     as sns\n",
    "# import imblearn    as imb\n",
    "# import matplotlib  as mpl\n",
    "# import pickle      as pickle\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "## Import necessary Modules, Functions and Objects from the Libraries. Examples given below ##\n",
    "# from numpy                         import loadtxt\n",
    "# from pandas                        import read_csv, read_excel\n",
    "# from pandas.plotting               import scatter_matrix\n",
    "# from datetime                      import datetime\n",
    "# from collections                   import Counter\n",
    "# from scipy.stats                   import boxcox as BoxCoxScaler\n",
    "# from imblearn.over_sampling        import SMOTE\n",
    "# from sklearn.metrics               import accuracy_score, roc_auc_score, make_scorer\n",
    "# from sklearn.metrics               import confusion_matrix, classification_report\n",
    "# from sklearn.preprocessing         import LabelEncoder, RobustScaler, StandardScaler, MinMaxScaler\n",
    "# from sklearn.model_selection       import ShuffleSplit, cross_val_score, train_test_split\n",
    "# from sklearn.model_selection       import GridSearchCV, KFold, StratifiedKFold, RepeatedStratifiedKFold\n",
    "# from matplotlib                    import pyplot as plt\n",
    "# --------- For Regression ----------\n",
    "# from sklearn.linear_model          import LinearRegression, LassoCV, RidgeCV, ElasticNetCV\n",
    "# from sklearn.neighbors             import KNeighborsRegressor\n",
    "# from sklearn.svm                   import SVR\n",
    "# from sklearn.tree                  import DecisionTreeRegressor\n",
    "# from sklearn.ensemble              import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "# from xgboost                       import XGBRegressor\n",
    "# -------- For Classification -------\n",
    "# from sklearn.linear_model          import LogisticRegression, SGDClassifier\n",
    "# from sklearn.neighbors             import KNeighborsClassifier\n",
    "# from sklearn.svm                   import SVC\n",
    "# from.naive_bayes                   import GaussianNB\n",
    "# from sklearn.tree                  import DecisionTreeClassifier\n",
    "# from sklearn.ensemble              import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "# from xgboost                       import XGBClassifier\n",
    "\n",
    "## Check the versions of the imported libraries\n",
    "# print(\"Versions of imported libraries:\")\n",
    "# print(\"Python:     {}\".format(sys.version))\n",
    "# print(\"Numpy:      {}\".format(np.__version__))\n",
    "# print(\"Pandas:     {}\".format(pd.__version__))\n",
    "# print(\"skLearn:    {}\".format(sk.__version__))\n",
    "# print(\"Scipy:      {}\".format(sp.__version__))\n",
    "# print(\"Seaborn:    {}\".format(sns.__version__))\n",
    "# print(\"Imblearn:   {}\".format(imb.__version__))\n",
    "# print(\"Matplotlib: {}\".format(mpl.__version__))\n",
    "\n",
    "# Optional settings\n",
    "# mpl.style.use('ggplot')\n",
    "# sns.set(style='whitegrid')\n",
    "# pd.set_option('display.max_columns', None, 'precision', 3)\n",
    "\n",
    "# print(__doc__)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "af4474bd-3cf2-4889-b7fc-6513c665af01",
   "metadata": {},
   "source": [
    "###   (2.2) USER DEFINED FUNCTIONS (UDFs)   ###\n",
    "\n",
    "# Define the necessary UDFs for this project, using standard naming conventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dc274f-2eea-437d-8273-63cc9992b84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "###   (2.3) DATA LOADING   ###\n",
    "\n",
    "## Load the necessary data files for this project. Examples given below ##\n",
    "# If the data file is in csv format, it can be loaded in 4 different ways\n",
    "#   - Using 'csv.reader' function from the standard library 'csv'\n",
    "#   - Using 'loadtxt'    function from 'numpy'  library\n",
    "#   - Using 'read_csv'   function from 'pandas' library\n",
    "#   - Using 'read_excel' function from 'pandas' library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d143264-70f7-4c32-8f5d-d94b37becca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "###   (2.4) EXPLORATORY DATA ANALYSIS (EDA)   ###\n",
    "\n",
    "## Understand the data with Descriptive Statistics. Examples given below ##\n",
    "# Use 'shape' function to see the dimensions of the datasets\n",
    "# Use 'head()' & 'tail()' functions to see the first & last few samples of the datasets\n",
    "# Use 'info()' function to see the basic information of the dataset\n",
    "# Use 'describe()' function to see the statistical summary of the datasets\n",
    "# Use 'Counter' or 'groupby()' function to see the class distribution of the datasets\n",
    "# Use 'df.is_null().sum()' to explore NA / NULL values in the dataset\n",
    "#     null_values     = pd.DataFrame(data=df.isnull().sum(), columns=['NULL count'])\n",
    "#     null_values_per = pd.DataFrame(round(df.isnull().sum() / len(df) * 100, 2), columns=['NULL Percentage'])\n",
    "#     null_values_df = pd.concat([null_values, null_values_per], axis=1)\n",
    "# Use 'df.cpy' to find the duplicates in the dataset\n",
    "#     print('Number of duplicates found:', (len(df) - len(dup_df))\n",
    "# Use the following 'style' functions to visualize the pandas dataframes for better aesthetic\n",
    "#   - Hiding function [hide_index(), hide_columns()]\n",
    "#   - Highlight function [highlight_max(), highlight_min(), highlight_null()]\n",
    "#   - Gradient function [background_gradient()]\n",
    "\n",
    "## Understand the data with Visualizations ##\n",
    "# Draw Univariate plots to better understand each attribute\n",
    "#   - Draw 'box and whisker plots\n",
    "#   - Draw 'histograms'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b41e650-4563-44c7-8810-8bddd2d0387d",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "<br>\n",
    "\n",
    "<[ [Stage-1: Business Understanding](07.00-mlpg-Stage-1-Business-Understanding.ipynb) | [Contents and Acronyms](00.00-mlpg-Contents-and-Acronyms.ipynb) | [Stage-3: Research](09.00-mlpg-Stage-3-Research.ipynb) ]>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c04eabf-a52d-47d8-b981-387e07923447",
   "metadata": {},
   "source": [
    "<!--BOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures/MLPG-Book-Cover-Small.png\"><br>\n",
    "\n",
    "This notebook contains an excerpt from the **`Machine Learning Project Guidelines - For Beginners`** book written by *Balasubramanian Chandran*; the content is available [on GitHub](https://github.com/BalaChandranGH/Books/ML-Project-Guidelines)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dfa775-b1aa-4dcf-adea-55a4b7d93a17",
   "metadata": {},
   "source": [
    "<br>\n",
    "<!--NAVIGATION-->\n",
    "\n",
    "<[ [Stage-2: Data Understanding](08.00-mlpg-Stage-2-Data-Understanding.ipynb) | [Contents and Acronyms](00.00-mlpg-Contents-and-Acronyms.ipynb) | [Stage-4: Data Preprocessing](10.00-mlpg-Stage-4-Data-Preprocessing.ipynb) ]>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ed55a1-13e7-4465-ae46-77096858ef89",
   "metadata": {},
   "source": [
    "# 9. Stage-3: Research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c58657-a356-4569-a405-a041726f0b81",
   "metadata": {},
   "source": [
    "Based on the type of the problem (_regression, classification or clustering, etc._) do research on the available algorithms and mention here the list of ML algorithms to be used to build the models. The final model will be selected based on their performances.\n",
    "* List down the names of algorithms, classifiers, and types of algorithms (linear, non-linear, ensemble, etc.) for the project\n",
    "* Identify the Evaluation metrics selected for the project with the reasons\n",
    "* An overall approach on how this project will be developed (similar to development methodology in traditional projects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a497df-7e8b-4ffc-b21f-3ae7be748583",
   "metadata": {},
   "source": [
    "## 9.1. List of selected algorithms to build models\n",
    "The following are the algorithms covering a variety of regression/classification strategies and techniques that have been selected for the project. All models will be developed with default parameters and trained. Only a few best will be selected for algorithm tuning based on their performances (evaluation metrics). Then, each of those models will be individually tuned to minimize error. The final model will be selected based on their evaluation metrics on training and test datasets. Select the algorithms based on the type of problem you are trying to solve. Commonly used algorithms are:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b95bd7b-7290-48a2-92d0-799356276b28",
   "metadata": {},
   "source": [
    "### 9.1.1. Regression algorithms\n",
    "```\n",
    " 1) Linear Regression (LR)          LinearRegression()            - Linear\n",
    " 2) Lasso (Lasso)                   LassoCV()                     - Linear\n",
    " 3) Ridge (Ridge)                   RidgeCV()                     - Linear\n",
    " 4) ElasticNet (EN)                 ElasticNetCV()                - Linear\n",
    " 5) K-Nearest Neighbors (KNN)       KNeighborsRegressor()         - Non-linear\n",
    " 6) Supprt Vector Machines (SVM)    SVR()                         - Non-linear\n",
    " 7) Decision Trees (DT)             DecisionTreeRegressor()       - Non-linear\n",
    " 8) Random Forest (RF)              RandomForestRegressor()       - Ensemble - Bagging\n",
    " 9) Gradient Boosting (GB)          GradientBoostingRegressor()   - Ensemble - Boosting\n",
    "10) Extreme Boosting (XGB)          XGBRegressor()                - Ensemble – Boosting\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774a60a8-7e50-4151-ae76-d51614add73d",
   "metadata": {},
   "source": [
    "### 9.1.2. Classification algorithms\n",
    "```\n",
    " 1) Logistic Regression (LR)        LogisticRegression()          - Simple Linear\n",
    " 2) SGD Classifier (SGD)            SGDClassifier()               - Simple Linear\n",
    " 3) K-Nearest Neighbors (KNN)       KNeighborsClassifier()        - Nonlinear\n",
    " 4) Support Vector Machines (SVM)   SVC()                         - Nonlinear\n",
    " 5) Gaussian Naive Bayes (NB)       GaussianNB()                  - Nonlinear\n",
    " 6) Decision Trees (DT)             DecisionTreeClassifier()      - Nonlinear\n",
    " 7) Random Forest Trees (RF)        RandomForestClassifier()      - Ensemble Bagging\n",
    " 8) Gradient Boosting (GB)          GradientBoostingClassifier()  - Ensemble Boosting   \n",
    " 9) AdaBoost                        AdaBoostClassifier()          - Ensemble Boosting\n",
    "10) Extreme Boosting (XGB)          XGBClassifier()               - Ensemble Boosting\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d46f57-d18d-45ad-9752-b2dac315605d",
   "metadata": {},
   "source": [
    "## 9.2. List of model evaluation metrics\n",
    "**Performance/Evaluation Metric:**\n",
    "* An evaluation metric is a way to quantify the performance of a predictive model\n",
    "* Evaluation metric ≠ Loss function\n",
    "* There is no \"one fits all\" evaluation metric\n",
    "* Get to know your data\n",
    "* Keep in mind the business objective of your ML problem\n",
    "\n",
    "Select one or more metrics based on the problem type and business priorities. Commonly used metrics are:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8863ffb6-6bec-4b03-b9e3-9118f5956a77",
   "metadata": {},
   "source": [
    "![](figures/MLPG-ModelEvalMetrics.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dca025-434b-4d53-8fd9-0a91748bea03",
   "metadata": {},
   "source": [
    "**NOTE:**\n",
    "* CV is a cross-validation score and, for regression, the scorer can be anything such as `R^2, MAE, MSE, RMSE, and RMSLE`\n",
    "* CV is a cross-validation score and, for classification, the scorer can be anything such as `Accuracy, ROC-AUC, PR-AUC, Logloss`, etc.\n",
    "* The following are not metrics, but they help to gain insight into the type of errors a model is making\n",
    "  - `Confusion matrix`\n",
    "  - `Classification report (produces Precision, Recall, F1 scores)`\n",
    "* Algorithm `run-time is also a metric`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc474195-eda0-493f-bad3-828337cff11a",
   "metadata": {},
   "source": [
    "### 9.2.1. Regression model evaluation metrics\n",
    "* **R^2, MAE, MSE, RMSE,** and **RMSLE** can be calculated independently using sklearn\n",
    "* **Cross-Validation** can be calculated using any of the independent metrics mentioned above\n",
    "* **Bias** and **Variance** are found by comparing the calculated evaluation metrics for Training datasets (_`X_train, y_train`_) and Test datasets (_`X_test, y_test`_) separately using any of the 5 independent metrics mentioned above\n",
    "  - **Bias Error (Underfitting)**: Bias is the simplifying assumptions made by a model to make the target function easier to learn\n",
    "    - `Low Bias`: Suggests fewer assumptions about the form of the target function (too simple)<br>\n",
    "    _Algorithms include Decision Trees, k-Nearest Neighbors, and SVMs_\n",
    "    - `High-Bias`: Suggests more assumptions about the form of the target function (complex)<br>\n",
    "    _Algorithms include Linear Regression, Linear Discriminant Analysis, and Logistic Regression_\n",
    "  - **Variance Error (Overfitting)**: Variance is the amount that the estimate of the target function will change if different training data was used\n",
    "    - `Low Variance`: Suggests small changes to the estimate of the target function with changes to the training dataset (complex)<br>\n",
    "    _Algorithms include Linear Regression, Linear Discriminant Analysis, and Logistic Regression_\n",
    "    - `High Variance`: Suggests large changes to the estimate of the target function with changes to the training dataset (too complex)<br>\n",
    "    _Algorithms include Decision Trees, k-Nearest Neighbors, and SVMs_\n",
    "  - **Bias-Variance Trade-Off**: The goal of any supervised machine learning algorithm is to achieve low bias and low variance. In turn, the algorithm should achieve good prediction performance\n",
    "    - Linear ML algorithms often have a high bias but a low variance\n",
    "    - Nonlinear ML algorithms often have a low bias but a high variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041e9165-8012-42b3-87b3-7042df274f3f",
   "metadata": {},
   "source": [
    "* **Residual Analysis:**\n",
    "  - Regression lines are the best fit for a set of data\n",
    "  - A residual value is a measure of how much a regression line vertically misses a data point\n",
    "  - A residual plot has the Residual Values on the vertical axis; the horizontal axis displays the independent variable and is typically used to find problems with regression\n",
    "  - Some data sets are not good candidates for regression, including:\n",
    "    - Heteroscedastic data (points at widely varying distances from the line)\n",
    "    - Data that is non-linearly associated\n",
    "    - Data sets with outliers\n",
    "  - The residual analysis is done during model validation or just before selecting the final model\n",
    "  - Residual equation = $Residual (\\epsilon) = y - \\hat{y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f855b36-beec-4d7f-8ef2-4ab65c582d6d",
   "metadata": {},
   "source": [
    "* **Normality Test (Q-Q Plot):**\n",
    "  - Helps to identify outliers/skewness\n",
    "  - This can be done during the Data Understanding stage to understand the raw data and can be done during model validation or just before selecting the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abfbcd0-b463-40b9-b8cc-d3f0bb6b1a9b",
   "metadata": {},
   "source": [
    "### 9.2.2. Classification model evaluation metrics\n",
    "**Threshold Metrics for Balanced / Imbalanced Classification**\n",
    "```\n",
    "Accuracy    = Correct Predictions / Total Predictions\n",
    "Error       = Incorrect Predictions / Total Predictions       (complement of Accuracy)\n",
    "Sensitivity = TruePositive / (TruePositive + FalseNegative)\n",
    "Specificity = TrueNegative / (FalsePositive + TrueNegative)   (complement to Sensitivity)\n",
    "G-Mean      = sqrt(Sensitivity * Specificity)                 (Geometric-mean that balances both)\n",
    "Precision   = TruePositive / (TruePositive + FalsePositive)\n",
    "Recall      = TruePositive / (TruePositive + FalseNegative)\n",
    "F-Measure   = (2 * Precision * Recall) / (Precision + Recall)\n",
    "```\n",
    "\n",
    "**Ranking Metrics for Balanced / Imbalanced Classification**\n",
    "```\n",
    "TruePositiveRate  = TruePositive / (TruePositive + FalseNegative)\n",
    "FalsePositiveRate = FalsePositive / (FalsePositive + TrueNegative)\n",
    "ROC AUC           = ROC Area Under Curve\n",
    "PR AUC            = Precision-Recall Area Under Curve\n",
    "```\n",
    "\n",
    "**Probabilistic Metrics for Balanced / Imbalanced Classification**\n",
    "```\n",
    "LogLoss         = -((1 – y) * log(1 – yhat) + y * log(yhat))  (for Binary classification)\n",
    "LogLoss         = -(sum c in C y_c * log(yhat_c))             (for multi-class classification)\n",
    "BrierScore      = 1/N * Sum i to N (yhat_i – y_i)^2\n",
    "BrierSkillScore = 1 – (BrierScore / BrierScore_ref)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5262d346-d650-4f9c-a543-1c45c954ef49",
   "metadata": {},
   "source": [
    "### 9.2.3. How to choose a Binary Classification model evaluation metric (for imbalanced datasets)\n",
    "* Are you predicting probabilities? \n",
    "  - Do you need class labels? \n",
    "    - Is the positive class more important? \n",
    "      - Use **Precision-Recall AUC**\n",
    "    - Are both classes important? \n",
    "      - Use **ROC AUC**\n",
    "  - Do you need probabilities? \n",
    "    - Use **Brier Score** and **Brier Skill Score**\n",
    "* Are you predicting class labels? \n",
    "  - Is the positive class more important? \n",
    "    - Are False Negatives and False Positives Equally Important? \n",
    "      - Use **F1-Measure**\n",
    "    - Are False Negatives More Important? \n",
    "      - Use **F2-Measure**\n",
    "    - Are False Positives More Important? \n",
    "      - Use **F0.5-Measure**\n",
    "  - Are both classes important? \n",
    "    - Do you have < 80%-90% Examples for the Majority Class? \n",
    "      - Use **Accuracy**\n",
    "    - Do you have > 80%-90% Examples for the Majority Class? \n",
    "      - Use **G-Mean**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b8c065-45e5-47a0-9ed0-b99800a92f0e",
   "metadata": {},
   "source": [
    "![](figures/MLPG-BinaryClassModelEvalMetric.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f79ac8a-144b-4d6f-968e-7e97e45be139",
   "metadata": {},
   "source": [
    "## 9.3. Deliverables from Stage-3\n",
    "* List of selected algorithms to build models\n",
    "* List of selected Evaluation metrics with reasons\n",
    "* Results of the overall research\n",
    "* Model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405886d0-ec24-4218-bf43-5dded3b18e66",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "<br>\n",
    "\n",
    "<[ [Stage-2: Data Understanding](08.00-mlpg-Stage-2-Data-Understanding.ipynb) | [Contents and Acronyms](00.00-mlpg-Contents-and-Acronyms.ipynb) | [Stage-4: Data Preprocessing](10.00-mlpg-Stage-4-Data-Preprocessing.ipynb) ]>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

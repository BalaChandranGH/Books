{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8387d42-2631-43ed-8e30-0d1db076d963",
   "metadata": {},
   "source": [
    "<!--BOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"figures/MLPG-Book-Cover-Small.png\"><br>\n",
    "\n",
    "This notebook contains an excerpt from the **`Machine Learning Project Guidelines - For Beginners`** book written by *Balasubramanian Chandran*; the content is available [on GitHub](https://github.com/BalaChandranGH/Books/ML-Project-Guidelines)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee0e947-9221-475c-b445-0253ba160aa9",
   "metadata": {},
   "source": [
    "<br>\n",
    "<!--NAVIGATION-->\n",
    "\n",
    "<[ [Stage-6: Model Training](12.00-mlpg-Stage-6-Model-Training.ipynb) | [Contents and Acronyms](00.00-mlpg-Contents-and-Acronyms.ipynb) | [Stage-8: Model Evaluation](14.00-mlpg-Stage-8-Model-Evaluation.ipynb) ]>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cde33fb-5c18-4ce0-af27-ae6330a744c7",
   "metadata": {},
   "source": [
    "# 13. Stage-7: Model Refinement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7438ea-29ab-42cd-9315-79717abebb90",
   "metadata": {},
   "source": [
    "ML team owns full responsibility for this stage. During this stage, two main activities are performed:\n",
    "  1. Based on the metrics generated at Stage 6, the models are compared and initial selections are made\n",
    "  2. The selected models are refined to improve their performances using _`Training datasets`_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcabff80-2f03-4ef5-a48c-d505b9de5b2f",
   "metadata": {},
   "source": [
    "## 13.1. Hyperparameters optimization\n",
    "### 13.1.1. Differences between Model Parameters and Model Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d10f32a-6139-4775-a67a-a01da8d62b27",
   "metadata": {},
   "source": [
    "![](figures/MLPG-DiffParamsHyperparams.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52300fb7-85ff-4ad0-99ff-79e1b268d7d4",
   "metadata": {},
   "source": [
    "### 13.1.2. Hyperparameters-Tuning for Classification Algorithms\n",
    "`A model is a hypothesis and its parameters allow us to tailor the hypothesis (i.e., the behavior of the algorithm) to a specific dataset.`\n",
    "* The more hyperparameters of an algorithm that one needs to tune, the slower the tuning process is. Therefore, it is desirable to select a minimum subset of model hyperparameters to search or tune\n",
    "* Not all model hyperparameters are equally important. Some hyperparameters have an outsized effect on the behavior, and in turn, the performance of an ML algorithm\n",
    "* As an ML practitioner, one must know which hyperparameters to focus on to get a good result quickly\n",
    "\n",
    "The following table summarizes the suggestions for hyperparameters-tuning for 7 Classification algorithms. Please note, that the list of algorithms and the hyperparameters are not exhaustive; these are just examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20e36eb-9d1d-4352-b00e-63b23810de9c",
   "metadata": {},
   "source": [
    "![](figures/MLPG-HyperparamsTuning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441b7949-5779-4f05-8851-a2655b5a0de6",
   "metadata": {},
   "source": [
    "### 13.1.3. Hyperparameters Optimization with Random Search and Grid Search\n",
    "#### 13.1.3.1. Scikit-Learn API for Hyperparameter Optimization\n",
    "* Sklearn provides the _`RandomizedSearchCV`_ for random search and _`GridSearchCV`_ for grid search.\n",
    "* Both techniques evaluate models for a given hyperparameter vector using cross-validation, hence the “CV” suffix of each class name\n",
    "* Both classes require two arguments: `Model` and `Search space`; This is defined as a `dictionary` where the names are the hyperparameter arguments to the model and the values are discrete values or distribution of values to sample in the case of a random search\n",
    "* Use _cross-validation_ objects for model evaluation,\n",
    "  - Use _`RepeatedStratifiedKFold`_ class for the **Classification** tasks\n",
    "  - Use _`RepeatedKFold`_ class for the **Regression** tasks\n",
    "* Both hyperparameter optimization classes also provide a scoring argument that takes a string indicating the metric to optimize\n",
    "  - For classification, this is a positive measure, such as _`accuracy`_, and the metric must be maximizing, meaning better models result in larger scores\n",
    "  - For regression, this is a negative error measure, such as _`neg_mean_absolute_error`_ for a negative version of the mean absolute error, where values closer to zero represent less prediction error by the model\n",
    "* The search can be made parallel, e.g. use all of the CPU cores by specifying the _`n_jobs`_ argument as an integer with the number of cores in your system, e.g. 8. Or you can set it to be -1 to automatically use all of the cores in your system\n",
    "* Once defined, the search is performed by calling the _`fit()`_ function and providing a dataset used to train and evaluate model hyperparameter combinations using cross-validation\n",
    "* Running the search may take minutes or hours, depending on the size of the search space and the speed of your hardware. You’ll often want to tailor the search to how much time you have rather than the possibility of what could be searched\n",
    "* At the end of the search, you can access all of the results via attributes on the class. Perhaps the most important attributes are the **best score** observed and the **hyperparameters** that achieved the best score\n",
    "* Once you know the set of hyperparameters that achieve the best result, you can then define a new model, set the values of each hyperparameter, then fit the model on all available data. This model can then be used to make predictions on new data\n",
    "* _`GridSearchCV`_ is time efficient and produces good results\n",
    "* _`RandomizedSearchCV`_ takes more time but produces better results\n",
    "* In addition to the hyperparameters mentioned in the above table, the _`alpha`_  & _`gamma`_ hyperparameters can also be used for SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8950424d-b772-49b6-bc39-26f9ececf8da",
   "metadata": {},
   "source": [
    "#### 13.1.3.2. Random Search for Classification (sample code)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "47bcf159-66ac-4539-b77c-25225409ec9b",
   "metadata": {},
   "source": [
    "### Source: https://machinelearningmastery.com/hyperparameter-optimization-with-random-search-and-grid-search/ ###\n",
    "# Random search logistic regression model on the sonar dataset\n",
    "from scipy.stats             import loguniform\n",
    "from pandas                  import read_csv\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Load dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/sonar.csv'\n",
    "df  = read_csv(url, header=None)\n",
    "# Split into input and output elements\n",
    "data = df.values\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "\n",
    "# Define model\n",
    "Model = LogisticRegression()\n",
    "# Define evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Define search space\n",
    "space            = dict()\n",
    "space['solver']  = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
    "space['C']       = loguniform(1e-5, 100)\n",
    "\n",
    "# Define search\n",
    "search = RandomizedSearchCV(model, space, n_iter=500, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
    "# Execute search\n",
    "result = search.fit(X, y)\n",
    "\n",
    "# Summarize results\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77110bd-528e-4859-8b91-c85223fa7ed6",
   "metadata": {},
   "source": [
    "#### 13.1.3.3. Grid Search for Classification (sample code)\n",
    "* Using the grid search is much like using the random search for classification\n",
    "* The main difference is that the search space must be a discrete grid to be searched. This means that instead of using a log-uniform distribution for C, we can specify discrete values on a log scale"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b186ec2c-dfa7-4158-8b83-a192971cb70a",
   "metadata": {},
   "source": [
    "### Source: https://machinelearningmastery.com/hyperparameter-optimization-with-random-search-and-grid-search/ ###\n",
    "# Grid search logistic regression model on the sonar dataset\n",
    "from pandas                  import read_csv\n",
    "from sklearn.linear_model    import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/sonar.csv'\n",
    "df  = read_csv(url, header=None)\n",
    "# Split into input and output elements\n",
    "data = df.values\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "\n",
    "# Define model\n",
    "model = LogisticRegression()\n",
    "# Define evaluation\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Define search space\n",
    "space            = dict()\n",
    "space['solver']  = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "space['penalty'] = ['none', 'l1', 'l2', 'elasticnet']\n",
    "space['C']       = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "\n",
    "# Define search\n",
    "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)\n",
    "# Execute search\n",
    "result = search.fit(X, y)\n",
    "\n",
    "# Summarize results\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6ad47b-1702-43fa-b1ec-423b8e29bc03",
   "metadata": {},
   "source": [
    "#### 13.1.3.4. Random Search for Regression (sample code)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a7650fcb-5318-4fc4-820d-039d2f450561",
   "metadata": {},
   "source": [
    "### Source: https://machinelearningmastery.com/hyperparameter-optimization-with-random-search-and-grid-search/ ###\n",
    "# Random search linear regression model on the auto insurance dataset\n",
    "from scipy.stats             import loguniform\n",
    "from pandas                  import read_csv\n",
    "from sklearn.linear_model    import Ridge\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Load dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/auto-insurance.csv'\n",
    "df  = read_csv(url, header=None)\n",
    "# Split into input and output elements\n",
    "data = df.values\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "\n",
    "# Define model\n",
    "model = Ridge()\n",
    "# Define evaluation\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Define search space\n",
    "space                  = dict()\n",
    "space['solver']        = ['svd', 'cholesky', 'lsqr', 'sag']\n",
    "space['alpha']         = loguniform(1e-5, 100)\n",
    "space['fit_intercept'] = [True, False]\n",
    "space['normalize']     = [True, False]\n",
    "\n",
    "# Define search\n",
    "search = RandomizedSearchCV(model, space, n_iter=500, scoring='neg_mean_absolute_error', n_jobs=-1, cv=cv, random_state=1)\n",
    "# Execute search\n",
    "result = search.fit(X, y)\n",
    "\n",
    "# Summarize results\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e83bbc-cf62-4c2f-a18d-8dbc3cd8f160",
   "metadata": {},
   "source": [
    "#### 13.1.3.5. Grid Search for Regression (sample code)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "51da76f1-aad1-4142-8b49-fd165e56ac5c",
   "metadata": {},
   "source": [
    "### Source: https://machinelearningmastery.com/hyperparameter-optimization-with-random-search-and-grid-search/ ###\n",
    "# Grid search linear regression model on the auto insurance dataset\n",
    "from pandas                  import read_csv\n",
    "from sklearn.linear_model    import Ridge\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/auto-insurance.csv'\n",
    "df  = read_csv(url, header=None)\n",
    "# Split into input and output elements\n",
    "data = df.values\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "\n",
    "# Define model\n",
    "model = Ridge()\n",
    "# Define evaluation\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# Define search space\n",
    "space                  = dict()\n",
    "space['solver']        = ['svd', 'cholesky', 'lsqr', 'sag']\n",
    "space['alpha']         = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "space['fit_intercept'] = [True, False]\n",
    "space['normalize']     = [True, False]\n",
    "\n",
    "# Define search\n",
    "search = GridSearchCV(model, space, scoring='neg_mean_absolute_error', n_jobs=-1, cv=cv)\n",
    "# Execute search\n",
    "result = search.fit(X, y)\n",
    "\n",
    "# Summarize results\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032b0f9d-38de-4e0e-b655-95b0cb9362b9",
   "metadata": {},
   "source": [
    "**IMPORTANT NOTE**: _Apply any algorithm fine-tuning of hyperparameter technique on training & testing datasets separately to prevent DATA LEAKAGE. In other words, DO NOT apply algorithm fine-tuning techniques before splitting the datasets into training & testing datasets._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b078bc93-e356-4c6e-95f7-467ecbccf96d",
   "metadata": {},
   "source": [
    "## 13.2. Deliverables from Stage-7\n",
    "* Selected & refined models ready for evaluation using test datasets\n",
    "* Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2200b6-c6f9-4bd7-aab0-6bc08f3b97b1",
   "metadata": {},
   "source": [
    "## 13.3. Notebook development tips"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ae75a47-4ad4-4bea-9412-24356b98c5a2",
   "metadata": {},
   "source": [
    "###   MODEL REFINEMENT   ###\n",
    "\n",
    "# Improve the performance of the selected models by algorithm tuning\n",
    "\n",
    "# Improve the performance of the selected models by ensemble predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7a3746-9358-42fb-b885-c53a135a9f85",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "<br>\n",
    "\n",
    "<[ [Stage-6: Model Training](12.00-mlpg-Stage-6-Model-Training.ipynb) | [Contents and Acronyms](00.00-mlpg-Contents-and-Acronyms.ipynb) | [Stage-8: Model Evaluation](14.00-mlpg-Stage-8-Model-Evaluation.ipynb) ]>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
